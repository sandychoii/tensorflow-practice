{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SqhFOxexRmk7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, FalsePositives, FalseNegatives, TruePositives, TrueNegatives, Precision, Recall, AUC\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, split=['train'], shuffle_files=True)"
      ],
      "metadata": {
        "id": "stQcMAiG1hUN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_SIZE = len(dataset[0])"
      ],
      "metadata": {
        "id": "LLL2-bRx2Q92"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.6\n",
        "VAL_RATIO = 0.2\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n",
        "  return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
        "\n",
        "IM_SIZE = 224\n",
        "def resize_rescale(image, label):\n",
        "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label\n",
        "\n",
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=8).batch(BATCH_SIZE)\n",
        "# test_dataset = test_dataset.shuffle(buffer_size=8).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "AMkDAjnqRomE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(Layer):\n",
        "  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\n",
        "    self.conv1 = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=activation)\n",
        "    self.batch1 = BatchNormalization()\n",
        "    self.pool1 = MaxPool2D(pool_size=pool_size, strides=strides)\n",
        "\n",
        "    self.conv2 = Conv2D(filters=filters*2, kernel_size=kernel_size, strides=strides, padding=padding, activation=activation)\n",
        "    self.batch2 = BatchNormalization()\n",
        "    self.pool2 = MaxPool2D(pool_size=pool_size, strides=strides)\n",
        "\n",
        "  def call(self, x, training):\n",
        "    x = self.conv1(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.batch2(x)\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "EQ0NyCuXRwcI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LenetModel(Model):\n",
        "  def __init__(self):\n",
        "    super(LenetModel, self).__init__()\n",
        "\n",
        "    self.feature_extractor = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "    self.dense1 = Dense(100, activation='relu')\n",
        "    self.batch1 = BatchNormalization()\n",
        "\n",
        "    self.dense2 = Dense(10, activation='relu')\n",
        "    self.batch2 = BatchNormalization()\n",
        "\n",
        "    self.dense3 = Dense(1, activation='sigmoid')\n",
        "\n",
        "  def call(self, x, training):\n",
        "    x = self.feature_extractor(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.dense2(x)\n",
        "    x = self.batch2(x)\n",
        "    x = self.dense3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "J_8CQHGYR0Cn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_sub_classed = LenetModel()"
      ],
      "metadata": {
        "id": "FEiYfx06wWhD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_sub_classed(tf.zeros([1,224,224,3])) # build first\n",
        "lenet_sub_classed.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HkVTRi4R2Ki",
        "outputId": "2e688d7d-3391-4964-d94f-8672e57660f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"lenet_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extractor (FeatureE  multiple                 1488      \n",
            " xtractor)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  76038500  \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  multiple                 400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  1010      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  multiple                 40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,041,449\n",
            "Trainable params: 76,041,181\n",
            "Non-trainable params: 268\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Metrics"
      ],
      "metadata": {
        "id": "ztG-dgQEZy0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Negative -> no malaria\n",
        "- Positive -> malaria\n",
        "- False Negative: malaria actually, but predicts no malaria (worst scenario in this problem)\n",
        "- False Positive: no malaria, but predicts malaria\n",
        "- True Negative / True Positive"
      ],
      "metadata": {
        "id": "WXuIHWZgSkga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Precision = TP/(TP+FP)\n",
        "- Recall = TP/(TP+FN)\n",
        "- Accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
        "- F1-score = 2PR/(P+R)\n",
        "\n",
        "We want to lower the FN, maximize the recall.\n",
        "\n",
        "Accuracy does not give priority for FN or FP."
      ],
      "metadata": {
        "id": "9AKaBvimT04O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Plot\n",
        "\n",
        "1. Modify the threshold -> If we reduce the threshold for malaria, predicts malaria more. Reduces FN.\n"
      ],
      "metadata": {
        "id": "PFcfqSMqWExu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [TruePositives(name='tp'),\n",
        "           FalsePositives(name='fp'),\n",
        "           TrueNegatives(name='tn'),\n",
        "           FalseNegatives(name='fn'),\n",
        "           BinaryAccuracy(name='accuracy'),\n",
        "           Precision(name='precision'),\n",
        "           Recall(name='recall'),\n",
        "           AUC(name='auc')]"
      ],
      "metadata": {
        "id": "scKC3ETmZKE5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_sub_classed = tf.keras.models.load_model('lenet')"
      ],
      "metadata": {
        "id": "tDo5O5zY0txG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_sub_classed.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=metrics)\n",
        "history = lenet_sub_classed.fit(train_dataset, validation_data=val_dataset, epochs=1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxqKUPDRR5sk",
        "outputId": "64cf5b13-483c-43f2-c340-4c4e1a9f0f70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "517/517 [==============================] - 71s 106ms/step - loss: 0.4816 - tp: 6383.0000 - fp: 1945.0000 - tn: 6327.0000 - fn: 1879.0000 - accuracy: 0.7687 - precision: 0.7665 - recall: 0.7726 - auc: 0.8496 - val_loss: 0.6195 - val_tp: 2261.0000 - val_fp: 920.0000 - val_tn: 1828.0000 - val_fn: 502.0000 - val_accuracy: 0.7420 - val_precision: 0.7108 - val_recall: 0.8183 - val_auc: 0.8545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_ = test_dataset.batch(1)"
      ],
      "metadata": {
        "id": "Qohg9YoswbdP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_sub_classed.evaluate(test_dataset_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm2OMVV-TFDk",
        "outputId": "94b850db-8cd6-438b-9b17-72cd2b2a292e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5513/5513 [==============================] - 54s 7ms/step - loss: 0.6547 - tp: 2186.0000 - fp: 928.0000 - tn: 1829.0000 - fn: 570.0000 - accuracy: 0.7283 - precision: 0.7020 - recall: 0.7932 - auc: 0.8370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6547425389289856,\n",
              " 2186.0,\n",
              " 928.0,\n",
              " 1829.0,\n",
              " 570.0,\n",
              " 0.728278636932373,\n",
              " 0.7019910216331482,\n",
              " 0.7931784987449646,\n",
              " 0.8370429277420044]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lenet_sub_classed.save('lenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHCoRSWAynr5",
        "outputId": "8f1f04ec-e8e9-46fc-86b0-a0e1b743bf54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_1_layer_call_fn while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Confusion matrix"
      ],
      "metadata": {
        "id": "K-CFtVGOaUAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7yjGLeCxBQq",
        "outputId": "a49c16be-06fd-44c1-d252-1c0fd37c1776"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "inp = []\n",
        "for x,y in test_dataset.as_numpy_iterator():\n",
        "  labels.append(y)\n",
        "  inp.append(x)"
      ],
      "metadata": {
        "id": "OIToc5ojaTeB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S2vVXAozakS",
        "outputId": "5c5e0a4a-79b1-4e98-a391-debbc7edd7fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(inp).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJhqiCvUc07b",
        "outputId": "f9c63598-6348-47a0-a4cb-e3b69f29fedb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5513, 1, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(inp)[:, 0, ...].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN0cfctVvg5c",
        "outputId": "8487e690-b365-4e93-bb1a-7ef4abe784d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5513, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = lenet_sub_classed.predict(np.array(inp)[:, 0, ...])\n",
        "print(predicted.shape)"
      ],
      "metadata": {
        "id": "lAwPRHFMbvmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wq1-WKoyKyN",
        "outputId": "0b13a314-e07a-412f-c1a7-5682e41c90e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.07523643], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw30q9RUyDYx",
        "outputId": "9d1282c4-7c0a-4bec-90fb-5681580d5114"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 0])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "\n",
        "cm = confusion_matrix(labels[0], predicted > threshold)\n",
        "print(cm)\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "sns.heatmap(cm, annot=True,)\n",
        "plt.title('Confusion matrix - {}'.format(threshold))\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')"
      ],
      "metadata": {
        "id": "3zh9e3BTv1jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUs7kd2MyUo3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}