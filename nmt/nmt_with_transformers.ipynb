{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Layer, Embedding, LSTM, Dense\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FfDn5Ec1BaaY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 20000\n",
        "ENGLISH_SEQUENCE_LENGTH = 64\n",
        "FRENCH_SEQUENCE_LENGTH = 64\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE=8\n",
        "HIDDEN_UNITS = 256"
      ],
      "metadata": {
        "id": "6vfK-5mUBcMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "oO0gC49B6Y-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDIIG4gA5bGg",
        "outputId": "b05929da-4974-453b-c059-845bfa76b4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 13:30:17--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  20.1MB/s    in 0.4s    \n",
            "\n",
            "2023-07-18 13:30:17 (20.1 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvNXEGO26JQK",
        "outputId": "9128dd68-8c44-4084-da48-42ea722fb67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/dataset/fra.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgKY7xHL6T8h",
        "outputId": "dda0d55f-94b8-474f-9210-4e0b82652d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217975 /content/dataset/fra.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10000 /content/dataset/fra.txt > /content/dataset/fra_10000.txt"
      ],
      "metadata": {
        "id": "n7xmy7Vb6NCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "bq_39605BFNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9JUwY-YpI3",
        "outputId": "997c1fa5-981a-48e7-e0b9-fb868ae55548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TextLineDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "text_dataset = tf.data.TextLineDataset(\"/content/dataset/fra_10000.txt\")\n",
        "text_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snv_dM-2aYTR"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aFOE8IAbSkC"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy44fl-KcH4E"
      },
      "outputs": [],
      "source": [
        "def selector(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return {'input_1':split_text[0:1], 'input_2': '[start] ' + split_text[1:2]}, split_text[1:2]+' [end]'\n",
        "  # {english, french(with start)}, french(with end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnBYhak8cVy9"
      },
      "outputs": [],
      "source": [
        "split_dataset = text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvtskdL_cZz-",
        "outputId": "c7921d17-a5c4-4ac6-f859-fd7be722ee05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! [end]'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. [end]'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! [end]'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTlSs7fLr-km"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return split_text[0:1], '[start] ' + split_text[1:2]+' [end]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T25y0AxGsL70"
      },
      "outputs": [],
      "source": [
        "init_dataset = text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BdqtDKjsR8_",
        "outputId": "b8b71eea-22d0-478c-c61d-fcb1e2635036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Va ! [end]'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Marche. [end]'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] En route ! [end]'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNUWQXjVbZTj"
      },
      "outputs": [],
      "source": [
        "english_training_data = init_dataset.map(lambda x,y : x) # input x,y and output x # only for english\n",
        "english_vectorize_layer.adapt(english_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VvhYD2JooYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c69f937-c5db-4305-9ab2-1866e3452165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# check the vectorize layer\n",
        "english_vectorize_layer.get_vocabulary()[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg3C1P8Ico1w"
      },
      "outputs": [],
      "source": [
        "french_training_data = init_dataset.map(lambda x,y : y) # input x,y and output x # only for english\n",
        "french_vectorize_layer.adapt(french_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO5ev4F9cx4v"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs, output):\n",
        "  return {'input_1' :english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2': french_vectorize_layer(inputs['input_2'])}, french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6PIbqDdoYuC"
      },
      "outputs": [],
      "source": [
        "dataset = split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJvbG2Gss_aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08915e74-99b0-449b-9366-967e48f70c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[ 2, 39,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[39,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 224,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[224,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2,  22, 270,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[ 22, 270,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "# check if each inputs are mapped with the adapted vectorizer\n",
        "for i in dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch/Split"
      ],
      "metadata": {
        "id": "jgFS-MqDAzKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "NUM_BATCHES=int(10000/BATCH_SIZE)\n",
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ],
      "metadata": {
        "id": "iyPS6TveAy9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concepts in Transformer"
      ],
      "metadata": {
        "id": "fXScyoWgE9ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-attention\n",
        "- Problem of seq2seq model\n",
        "    - When transferring information from the encoder to the decoder, relying on just the single context vector will cause much information to be lost by the time we get to the last unit.\n",
        "- Attention mechanism\n",
        "    - Find how similar words are in the encoder and with the decoder.\n",
        "    - Attention Score: How each encoder tokens influences the decoder token\n",
        "    - Query: Previous hidden state of decoder\n",
        "    - Key, Value: Encoder hidden state\n",
        "- Self-attention\n",
        "    - Find how similar is each and every word in the input to one another\n",
        "    - Remove RNN -> Capable of parallel processing\n",
        "\n",
        "![scaled_dot](https://jamesmccaffrey.files.wordpress.com/2020/09/sdpa_picture_and_equation.jpg?w=584&h=246)\n",
        "\n",
        "See this:https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms"
      ],
      "metadata": {
        "id": "pE2bmbzWDrXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head Attention"
      ],
      "metadata": {
        "id": "lHr6FLiFDw0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![multi_head](https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png)\n",
        "\n",
        "(seq_len, embed_dim) -> (seq_len, hs_linear) -> (seq_len, hs_linear * h)"
      ],
      "metadata": {
        "id": "y3Ggk1OPDzyv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gwDkqTnFDuQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer Normalization"
      ],
      "metadata": {
        "id": "BWRbj6XuE0jF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Batch Normalization is not used in NLP -> NLP batch statistics exhibit \"large variance\" throughout training (poor performance) (From powerNorm paper)\n",
        "- Layer Normalization normalizes across the features of a single batch"
      ],
      "metadata": {
        "id": "WNAYaEZCE57n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "9tbnlE6zD3bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding\n"
      ],
      "metadata": {
        "id": "PsR7nMb9EKSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고: https://www.blossominkyung.com/deeplearning/transfomer-positional-encoding\n"
      ],
      "metadata": {
        "id": "pinL5rUfIHUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://machinelearningmastery.com/wp-content/uploads/2022/01/PE3.png)"
      ],
      "metadata": {
        "id": "rbP6vrdwJNdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "G0H4o3-XLjll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 64\n",
        "def positional_encoding(model_size, SEQ_LEN):\n",
        "  output = []\n",
        "  for pos in range(SEQ_LEN):\n",
        "    PE = np.zeros((model_size)) # (512)\n",
        "    for i in range(model_size):\n",
        "      if i%2 == 0:\n",
        "        PE[i] = np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i] = np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output += [tf.expand_dims(PE, axis=0)] # (1,512)\n",
        "  out = tf.concat(output, axis=0) # (SEQ_LEN, model_size)\n",
        "  out = tf.expand_dims(out, axis=0) # (1, SL, ms)\n",
        "  return tf.cast(out, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "G6fIllMRK5KZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = [np.zeros((1,512)), np.zeros((1,512))]\n",
        "tf.concat(o, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rAColZOKnNe",
        "outputId": "54a0294f-1f4d-4f8c-e280-5645682da65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float64, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding(512).shape"
      ],
      "metadata": {
        "id": "y-XNAshKM5Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdf17c8-cce2-47f6-8d97-d84310f335fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "daDrgfLvHOjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, vocab_size, sequence_length, embedding_dim):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "    self.vocab_size = vocab_size\n",
        "    self.sequence_length = sequence_length\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded = self.embedding(inputs) # (bs, seq_len, embed_dim)\n",
        "    positions = positional_encoding(self.embedding_dim, self.sequence_length) # (bs, seq_len, embed_dim)\n",
        "    return embedded + positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    mask = tf.math.not_equal(inputs, 0) # False where 0\n",
        "    # Create a matrix\n",
        "    mask1 = mask[:, :, tf.newaxis] # (bs, seq_len, 1)\n",
        "    mask2 = mask[:, tf.newaxis, :] # (bs, 1, seq_len)\n",
        "    attention_mask = mask1 & mask2 # (bs, seq_len, seq_len) # all the padded values are False otherwise True\n",
        "    return attention_mask"
      ],
      "metadata": {
        "id": "pgSXp3yGLEMM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebd = Embeddings(vocab_size=20000, sequence_length=64, embedding_dim=256)\n",
        "ebd(tf.zeros((5, 64))).shape\n",
        "# ebd.compute_mask(tf.zeros((5, 64)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28I9qq9DNdMP",
        "outputId": "19514147-9727-4c2f-e129-3ba823770917"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 64, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### compute_mask : creates 0 mask for padded values"
      ],
      "metadata": {
        "id": "pWIANLyRK5wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[2, 231, 5, 7, 8, 0, 0, 0]])\n",
        "mask = tf.math.not_equal(a, 0) # true if not 0\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHc79txSHJ3C",
        "outputId": "651965a4-c3a3-49f7-c589-35b28345cf8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=bool, numpy=array([[ True,  True,  True,  True,  True, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.newaxis works same with tf.expand_dims\n",
        "mask1 = mask[:,:, tf.newaxis] # (1, 8, 1)\n",
        "mask2 = mask[:, tf.newaxis, :] # (1, 1, 8)\n",
        "print(mask1&mask2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q9ONYRmKJ_C",
        "outputId": "2f3ffaaa-9af5-4142-8a3c-5be924bd34fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ True  True  True  True  True False False False]\n",
            "  [ True  True  True  True  True False False False]\n",
            "  [ True  True  True  True  True False False False]\n",
            "  [ True  True  True  True  True False False False]\n",
            "  [ True  True  True  True  True False False False]\n",
            "  [False False False False False False False False]\n",
            "  [False False False False False False False False]\n",
            "  [False False False False False False False False]]], shape=(1, 8, 8), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqZNdmOIKYTD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}