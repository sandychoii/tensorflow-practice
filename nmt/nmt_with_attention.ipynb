{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Embedding, LSTM, Dense\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FfDn5Ec1BaaY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 20000\n",
        "ENGLISH_SEQUENCE_LENGTH = 64\n",
        "FRENCH_SEQUENCE_LENGTH = 64\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE=8"
      ],
      "metadata": {
        "id": "6vfK-5mUBcMJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "oO0gC49B6Y-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDIIG4gA5bGg",
        "outputId": "5b75b670-de89-4b90-f214-bda5c9211826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-17 11:22:24--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  4.24MB/s    in 1.7s    \n",
            "\n",
            "2023-07-17 11:22:27 (4.24 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvNXEGO26JQK",
        "outputId": "d8071b23-1e6e-4555-a07f-f614373ecec2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/dataset/fra.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgKY7xHL6T8h",
        "outputId": "b4739e67-751a-4ce8-b54b-b6abfab99fe6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217975 /content/dataset/fra.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10000 /content/dataset/fra.txt > /content/dataset/fra_10000.txt"
      ],
      "metadata": {
        "id": "n7xmy7Vb6NCV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "bq_39605BFNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9JUwY-YpI3",
        "outputId": "d4a08847-56fb-4618-d030-5ebf1b0b0e6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TextLineDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "text_dataset = tf.data.TextLineDataset(\"/content/dataset/fra_10000.txt\")\n",
        "text_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "snv_dM-2aYTR"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_aFOE8IAbSkC"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Oy44fl-KcH4E"
      },
      "outputs": [],
      "source": [
        "def selector(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return {'input_1':split_text[0:1], 'input_2': '[start] ' + split_text[1:2]}, split_text[1:2]+' [end]'\n",
        "  # {english, french(with start)}, french(with end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EnBYhak8cVy9"
      },
      "outputs": [],
      "source": [
        "split_dataset = text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvtskdL_cZz-",
        "outputId": "5097ef23-e72d-4af2-f929-856161cface4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! [end]'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. [end]'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! [end]'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xTlSs7fLr-km"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return split_text[0:1], '[start] ' + split_text[1:2]+' [end]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T25y0AxGsL70"
      },
      "outputs": [],
      "source": [
        "init_dataset = text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BdqtDKjsR8_",
        "outputId": "22466800-a4b8-4016-b042-09f354914416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Va ! [end]'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] Marche. [end]'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'[start] En route ! [end]'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fNUWQXjVbZTj"
      },
      "outputs": [],
      "source": [
        "english_training_data = init_dataset.map(lambda x,y : x) # input x,y and output x # only for english\n",
        "english_vectorize_layer.adapt(english_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-VvhYD2JooYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc02f29e-e95c-4cdd-8627-da25bca1a24c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# check the vectorize layer\n",
        "english_vectorize_layer.get_vocabulary()[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eg3C1P8Ico1w"
      },
      "outputs": [],
      "source": [
        "french_training_data = init_dataset.map(lambda x,y : y) # input x,y and output x # only for english\n",
        "french_vectorize_layer.adapt(french_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dO5ev4F9cx4v"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs, output):\n",
        "  return {'input_1' :english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2': french_vectorize_layer(inputs['input_2'])}, french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C6PIbqDdoYuC"
      },
      "outputs": [],
      "source": [
        "dataset = split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OJvbG2Gss_aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24e35ba-1db3-45c5-95f9-a93f0c142957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[ 2, 39,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[39,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 224,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[224,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2,  22, 270,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[ 22, 270,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "# check if each inputs are mapped with the adapted vectorizer\n",
        "for i in dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch/Split"
      ],
      "metadata": {
        "id": "jgFS-MqDAzKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "NUM_BATCHES=int(10000/BATCH_SIZE)\n",
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ],
      "metadata": {
        "id": "iyPS6TveAy9a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9J7nzQF4BIgQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "yDYaC4vH6jUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problem of RNN: Depend on one context vector\n",
        "- \"Neural Machine Translation by Jointly Learning to Align and Translate\" -> Bahdanau Attention paper\n",
        "- https://wikidocs.net/73161\n",
        "- Attention mechanism: each and every output unit is linked to all the input units via attention with vector\n",
        "- Bahdanau attention = addtitive attention"
      ],
      "metadata": {
        "id": "HKghyxbB6kyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim) # (bs, seq_len, embed_dim)\n",
        "    self.lstm = LSTM(self.units, return_sequences=True) # (bs, seq_len, hs)\n",
        "\n",
        "  def call(self, input):\n",
        "    x = self.embedding(input)\n",
        "    outputs = self.lstm(x) ##?\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "40s256yd6WU7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_UNITS = 256\n",
        "encoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS)\n",
        "enc_out = encoder(tf.zeros([8, 64]))\n",
        "enc_out.shape # (bs, seq_len, hs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwXqMcx1w321",
        "outputId": "383ca875-ef05-4bdd-b388-b4895e677cf1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 64, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w_a = Dense(1)\n",
        "    self.w_b = Dense(self.units)\n",
        "    self.w_c = Dense(self.units)\n",
        "\n",
        "  def call(self, prev_dec_state, enc_state): # (bs, hs), (bs, seq_len, hs)\n",
        "    scores = self.w_a(\n",
        "        tf.nn.tanh(\n",
        "            self.w_b(tf.expand_dims(prev_dec_state, -2)) # (bs, 1, hs)\n",
        "            + self.w_c(enc_state)\n",
        "        )\n",
        "    ) # (bs, seq_len, 1)\n",
        "\n",
        "    attention_distribution = tf.nn.softmax(scores, axis=1) # (bs, seq_len, 1) # attention values with every input sequence\n",
        "    context_vector = attention_distribution * enc_state # (bs, seq_len, hs)\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # (bs, hs)\n",
        "    # print(context_vector.shape)\n",
        "\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "bVoqmztXtpNR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(HIDDEN_UNITS)\n",
        "context_vector = attention(tf.zeros([8, 256]), enc_out)\n",
        "context_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnIb5bn24FX4",
        "outputId": "33080e7b-0ddb-4fa3-c7a6-7e983b9f89ca"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, units, sequence_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.units = units\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.lstm = LSTM(self.units, return_sequences=True, return_state=True)\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "    self.dense = Dense(self.vocab_size, activation=\"softmax\")\n",
        "\n",
        "  def call(self, enc_state, prev_dec_state, shifted_target): ## teacher forcing\n",
        "    shifted_target = self.embedding(shifted_target) # (bs, seq_len, embed_dim)\n",
        "\n",
        "    outputs = []\n",
        "    for t in range(self.sequence_length):\n",
        "      context_vector = self.attention(prev_dec_state, enc_state) # (bs, hs)\n",
        "\n",
        "      # Bahdanau concatenates context vector and word embedding\n",
        "      dec_input = tf.concat([context_vector, shifted_target[:,t]], axis=-1) # (bs, hs + embed_dim)\n",
        "      output = self.lstm(tf.expand_dims(dec_input, 1)) # lstm accepts 3 dim # (bs, 1, hs)\n",
        "      #### need to check the output of lstm\n",
        "\n",
        "      outputs.append(output[0][:, 0])  # (bs, hs) * seq_len\n",
        "\n",
        "    outputs = tf.convert_to_tensor(outputs) # (seq_len, bs, hs)\n",
        "    outputs = tf.transpose(outputs, perm=[1,0,2]) # (bs, seq_len, hs)\n",
        "    outputs = self.dense(outputs) # (bs, seq_len, vocab_size)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "qUfMSjCz4nHP"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.zeros([8, 1, 256])[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IleLaMiiI6Ek",
        "outputId": "ff4682d2-4b2c-4072-fe2e-97940bb613b3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 256), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS, FRENCH_SEQUENCE_LENGTH)\n",
        "decoder(enc_out, tf.zeros([8, HIDDEN_UNITS]), tf.zeros([8, 64])).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSymygHvCmU9",
        "outputId": "0b829141-3169-4462-d16e-9dacccad3d4d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 64, 20000])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1Lat6mUDBpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}